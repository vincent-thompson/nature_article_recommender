{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T21:05:38.109487Z",
     "iopub.status.busy": "2020-10-30T21:05:38.109246Z",
     "iopub.status.idle": "2020-10-30T21:05:38.113216Z",
     "shell.execute_reply": "2020-10-30T21:05:38.112323Z",
     "shell.execute_reply.started": "2020-10-30T21:05:38.109460Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Article Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T15:00:44.848321Z",
     "iopub.status.busy": "2020-10-30T15:00:44.848071Z",
     "iopub.status.idle": "2020-10-30T15:00:44.856380Z",
     "shell.execute_reply": "2020-10-30T15:00:44.855303Z",
     "shell.execute_reply.started": "2020-10-30T15:00:44.848294Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_links(start, stop):\n",
    "    titles = []\n",
    "    urls=[]\n",
    "    for i in range(start, stop+1):\n",
    "        print(i)\n",
    "        ua = UserAgent()\n",
    "        user_agent = {'User-agent': ua.random}\n",
    "        url = f'https://www.nature.com/nature/articles?searchType=journalSearch&sort=PubDate&type=news&page={i}'\n",
    "        response = requests.get(url, headers = user_agent)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        page_articles = soup.findAll('article')\n",
    "        title_list = []\n",
    "        link_list=[]\n",
    "        for article in page_articles:\n",
    "            title_list.append(article.find('a').text.strip())\n",
    "            link_list.append(article.find('a')['href'])\n",
    "        titles += title_list\n",
    "        urls += link_list\n",
    "    return pd.DataFrame(data={'title':titles, 'url':urls})\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T21:03:47.628546Z",
     "iopub.status.busy": "2020-10-30T21:03:47.628288Z",
     "iopub.status.idle": "2020-10-30T21:03:47.631401Z",
     "shell.execute_reply": "2020-10-30T21:03:47.630686Z",
     "shell.execute_reply.started": "2020-10-30T21:03:47.628519Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = get_links(1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use links to get article text, and date published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-30T21:04:30.473059Z",
     "iopub.status.busy": "2020-10-30T21:04:30.472802Z",
     "iopub.status.idle": "2020-10-30T21:04:30.515886Z",
     "shell.execute_reply": "2020-10-30T21:04:30.514983Z",
     "shell.execute_reply.started": "2020-10-30T21:04:30.473032Z"
    }
   },
   "outputs": [],
   "source": [
    "df['comment_text'] = ['' for i in range(len(df.index))]\n",
    "df['year'] = [0 for i in range(len(df.index))]\n",
    "df['month'] = ['' for i in range(len(df.index))]\n",
    "df['day'] = [0 for i in range(len(df.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-02T14:48:16.307116Z",
     "iopub.status.busy": "2020-11-02T14:48:16.302444Z",
     "iopub.status.idle": "2020-11-02T14:48:16.373082Z",
     "shell.execute_reply": "2020-11-02T14:48:16.371419Z",
     "shell.execute_reply.started": "2020-11-02T14:48:16.305781Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = 'https://www.nature.com'\n",
    "for i, url in enumerate(new_df.url):\n",
    "    if i > 11201:\n",
    "        print(i)\n",
    "        full_url = base_url + url\n",
    "        ua = UserAgent()\n",
    "        user_agent = {'User-agent': ua.random}\n",
    "        try:\n",
    "            response = requests.get(full_url, headers = user_agent, allow_redirects=True)\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page, 'lxml')\n",
    "        except:\n",
    "            new_df.loc[i, 'comment_text'] = 'Unknown'\n",
    "\n",
    "\n",
    "        article_text = ''\n",
    "        article_body=''\n",
    "        \n",
    "        if soup.find('div', class_='article__body serif cleared'):\n",
    "            article_body = soup.find('div', class_='article__body serif cleared')\n",
    "        elif soup.find('div', class_='entry-content'):\n",
    "            article_body = soup.find('div', class_='entry-content')\n",
    "        elif soup.find('article'):\n",
    "            article_body = soup.find('article')\n",
    "        else:\n",
    "            article_text= 'Unknown'\n",
    "            print('Unknown')\n",
    "\n",
    "        if article_body:\n",
    "            paragraph_list = article_body.findAll('p', class_ = False)\n",
    "            for paragraph in paragraph_list:\n",
    "                if paragraph == paragraph_list[-1]:\n",
    "                    article_text += paragraph.text.strip()\n",
    "                else:\n",
    "                    article_text += (paragraph.text.strip() + ' ')\n",
    "\n",
    "\n",
    "        new_df.loc[i, 'comment_text'] = article_text\n",
    "\n",
    "        if soup.find('time'):\n",
    "            time = soup.find('time').text.split(' ')\n",
    "            new_df.loc[i, 'day'] = int(time[0])\n",
    "            new_df.loc[i, 'month'] = time[1]\n",
    "            new_df.loc[i, 'year'] = int(time[2])\n",
    "        elif soup.find('abbr', class_='published'):\n",
    "            time = soup.find('abbr').text.split(' ')\n",
    "            new_df.loc[i, 'day'] = int(time[0])\n",
    "            new_df.loc[i, 'month'] = time[1]\n",
    "            new_df.loc[i, 'year'] = int(time[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
